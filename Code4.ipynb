{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d60072b-b5ff-4abc-9aae-a9e18037e30f",
   "metadata": {},
   "source": [
    "### Using pandas, write a Python function to clean and preprocess a given DataFrame, which involves handling missing values, normalizing numerical columns, and encoding categorical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7141b469-c9ec-4052-b682-b43866e0d024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CGPA INTERACTIVE PRACTICAL KNOWLEDGE COMMUNICATION SKILLS JOB OFFER\n",
      "0  >=9         yes           very good                 good       NaN\n",
      "1  >=8         NaN                good             moderate       yes\n",
      "2  >=9          no             average                 poor        no\n",
      "3   <8          no                 NaN                 good       NaN\n",
      "4  >=8         yes                good             moderate       yes\n",
      "5  >=9         yes                good             moderate       yes\n",
      "6   <8         yes                good                  NaN        no\n",
      "7  NaN          no                 NaN                 good       yes\n",
      "8  >=8         yes                good                 good       yes\n",
      "9  >=8         yes             average                 good       yes\n",
      "check if null values are present or not: \n",
      "CGPA                    1\n",
      "INTERACTIVE             1\n",
      "PRACTICAL KNOWLEDGE     2\n",
      "COMMUNICATION SKILLS    1\n",
      "JOB OFFER               2\n",
      "dtype: int64\n",
      "\n",
      "replacing missing values: \n",
      "[['>=9' 'yes' 'very good' 'good' 'yes']\n",
      " ['>=8' 'yes' 'good' 'moderate' 'yes']\n",
      " ['>=9' 'no' 'average' 'poor' 'no']\n",
      " ['<8' 'no' 'good' 'good' 'yes']\n",
      " ['>=8' 'yes' 'good' 'moderate' 'yes']\n",
      " ['>=9' 'yes' 'good' 'moderate' 'yes']\n",
      " ['<8' 'yes' 'good' 'good' 'no']\n",
      " ['>=8' 'no' 'good' 'good' 'yes']\n",
      " ['>=8' 'yes' 'good' 'good' 'yes']\n",
      " ['>=8' 'yes' 'average' 'good' 'yes']]\n",
      "Encoding categorical data: \n",
      "Country variable: \n",
      "[[0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "Purchased variable: \n",
      "[2 1 0 2 1 1 0 1 1 1]\n",
      "\n",
      "Normalizing features: \n",
      "[[-0.57735027  1.29099445 -0.37796447  0.77459667  0.          1.29099445\n",
      "  -0.37796447 -0.57735027  1.73205081 -0.37796447 -0.37796447]\n",
      " [-0.57735027  1.29099445 -0.37796447  0.77459667  0.         -0.77459667\n",
      "   2.64575131 -0.57735027 -0.57735027 -0.37796447 -0.37796447]\n",
      " [-0.57735027 -0.77459667  2.64575131 -1.29099445  0.         -0.77459667\n",
      "  -0.37796447  1.73205081 -0.57735027 -0.37796447 -0.37796447]\n",
      " [-0.57735027  1.29099445 -0.37796447 -1.29099445  0.         -0.77459667\n",
      "  -0.37796447 -0.57735027 -0.57735027  2.64575131 -0.37796447]\n",
      " [ 1.73205081 -0.77459667 -0.37796447  0.77459667  0.         -0.77459667\n",
      "  -0.37796447 -0.57735027 -0.57735027 -0.37796447 -0.37796447]\n",
      " [ 1.73205081 -0.77459667 -0.37796447  0.77459667  0.          1.29099445\n",
      "  -0.37796447 -0.57735027  1.73205081 -0.37796447 -0.37796447]\n",
      " [-0.57735027 -0.77459667 -0.37796447 -1.29099445  0.         -0.77459667\n",
      "  -0.37796447  1.73205081 -0.57735027 -0.37796447 -0.37796447]\n",
      " [-0.57735027 -0.77459667 -0.37796447  0.77459667  0.          1.29099445\n",
      "  -0.37796447 -0.57735027 -0.57735027 -0.37796447  2.64575131]]\n",
      "[[ 1.73205081 -0.77459667 -0.37796447  0.77459667  0.          1.29099445\n",
      "  -0.37796447 -0.57735027 -0.57735027 -0.37796447 -0.37796447]\n",
      " [ 1.73205081 -0.77459667 -0.37796447 -1.29099445  1.          1.29099445\n",
      "  -0.37796447 -0.57735027  1.73205081 -0.37796447 -0.37796447]]\n",
      "\n",
      "check accuracy by applying classifier to know the data is preprocessed or not\n",
      "classification report:                precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00         2\n",
      "   macro avg       1.00      1.00      1.00         2\n",
      "weighted avg       1.00      1.00      1.00         2\n",
      "\n",
      "Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\davan\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "dataset=pd.read_csv(\"sample2.csv\")\n",
    "print(dataset)\n",
    "print(\"check if null values are present or not: \")\n",
    "print(dataset.isnull().sum())\n",
    "print()\n",
    "x=dataset.iloc[:,:-1].values\n",
    "y=dataset.iloc[:,-1].values\n",
    "print(\"replacing missing values: \")\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer=SimpleImputer(strategy='most_frequent')\n",
    "dataset=imputer.fit_transform(dataset)\n",
    "print(dataset)\n",
    "print(\"Encoding categorical data: \")\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "onehotencoder=OneHotEncoder(drop='first',sparse=False)\n",
    "x=onehotencoder.fit_transform(x)\n",
    "print(\"Country variable: \")\n",
    "print(x)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder=LabelEncoder()\n",
    "print(\"Purchased variable: \")\n",
    "y=labelencoder.fit_transform(y)\n",
    "print(y)\n",
    "print()\n",
    "print(\"Normalizing features: \")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=42,test_size=0.2)\n",
    "standardscaler=StandardScaler()\n",
    "x_train=standardscaler.fit_transform(x_train)\n",
    "x_test=standardscaler.transform(x_test)\n",
    "print(x_train)\n",
    "print(x_test)\n",
    "print()\n",
    "print(\"check accuracy by applying classifier to know the data is preprocessed or not\")\n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "knn= KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2 )  \n",
    "knn.fit(x_train, y_train)\n",
    "y_pred=knn.predict(x_test)\n",
    "print(\"classification report: \",classification_report(y_test,y_pred))\n",
    "print(\"Accuracy:\",accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393597bd-b4ca-447d-84a6-78459b3cfbf1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
